{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "surrounded-negative",
   "metadata": {},
   "source": [
    "# Zeth cadCAD simulations\n",
    "\n",
    "---------\n",
    "\n",
    "- **Author:** Antoine Rondelet (ar@clearmatics.com)\n",
    "- **Version:** 0.2.0\n",
    "\n",
    "---------\n",
    "\n",
    "In this notebook, we will simulate the evolution of a simplified blockchain system on which Zeth is deployed in order to better educate the choice of the various protocol parameters (number of input notes, number of output notes, depth of the Merkle tree etc). This notebook can be used for further experiments (using parameters which are not yet documented).\n",
    "\n",
    "This notebook is focused around some key questions regarding the blockchain state growth under different configurations. This is particularly important since the growth of the blockchain state is a key factor that impacts the number of nodes on the distributed system (it drives the HW requirements for existing nodes on the network as well as affects how easy it is for new nodes to join the network (i.e. sync a new node)).\n",
    "In other words, as the number of nodes on a blockchain \"boils down to convenience\", we are interested to see how convenient (easy/fast/cheap) it is to validate on a blockchain under various network assumptions. Studying the state growth provides valuable hints with that regard. Nevertheless, the reader is reminded that, by the very essence of modeling, we make several simplifying assumptions in the section below that will thus ignore various aspects of a \"real-life\" running system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-training",
   "metadata": {},
   "source": [
    "------------------\n",
    "\n",
    "<em><center>\"All models are wrong, but some are useful\"</center></em>\n",
    "<center>George E. P. Box.</center>\n",
    "\n",
    "------------------\n",
    "\n",
    "Hopefully this one is somewhat useful..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-albania",
   "metadata": {},
   "source": [
    "## Open questions\n",
    "\n",
    "This notebook is structured around some key open questions that aim to better understand the impact of Zeth on a blockchain system. Likewise, in a future work, we will be investigasting how well the privacy-preserving scalability solutions Zecale performs in term of both data compression and TPS.\n",
    "\n",
    "### Question 1\n",
    "\n",
    "After how much time does the Zeth merkle tree become full for a given Merkle tree depth?\n",
    "- Assumption: all blocks mined are full and only made of Zeth transactions\n",
    "\n",
    "### Question 2\n",
    "\n",
    "How does the chain state size compare when only Zeth transactions are used, as opposed to the case where only \"plain\" EOA-to-EOA Ethereum transactions are used?\n",
    "\n",
    "### Question 3\n",
    "\n",
    "What is the gas cost per byte for EoA-to-EoA transactions and for Zeth transactions?\n",
    "\n",
    "### Question 4\n",
    "\n",
    "After how much time does the chain data become higher that 1TB? (1TB is the max storage of the latest XPS-15 laptop. We use this threshold as an indicator to track after how much time running a node becomes inconvenient and requires some \"specialized\" HW)\n",
    "\n",
    "### Question 5\n",
    "\n",
    "What is the impact of Zeth on the TPS of the system?\n",
    "- Assumption: all blocks mined are full and only made of Zeth transactions\n",
    "\n",
    "### Question 6\n",
    "\n",
    "How well does Zecale compress the state (compared to \"vanilla Zeth\")? Furthermore:\n",
    "- How is TPS impacted when batching Zeth transactions with Zecale?\n",
    "- Are data compression and TPS moving in the same direction?\n",
    "\n",
    "**This question is answered in another notebook dedicated to Zecale**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-affiliation",
   "metadata": {},
   "source": [
    "## Setup code dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cadCAD configuration modules\n",
    "from cadCAD.configuration.utils import config_sim\n",
    "from cadCAD.configuration import Experiment\n",
    "from cadCAD import configs\n",
    "\n",
    "# cadCAD simulation engine modules\n",
    "from cadCAD.engine import ExecutionMode, ExecutionContext\n",
    "from cadCAD.engine import Executor\n",
    "\n",
    "# Analysis and plotting modules\n",
    "import pandas as pd\n",
    "import plotly\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# Misc\n",
    "## Pretty print function\n",
    "from pprint import pprint\n",
    "# Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "japanese-timber",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "### Zeth state\n",
    "\n",
    "We assume that the Zeth state ($\\zeta_z$) is only made of the following:\n",
    "\n",
    "- Zeth Merkle tree, simply modelled as a set of leaves nodes, i.e. Merkle tree Leaves Set (denoted $\\mathtt{MKLS}$). The full tree with intermediate nodes can be recovered by recursive hashing from the tree leaves.\n",
    "- Nullifiers set (denoted $\\mathtt{NS}$)\n",
    "- Roots set (denoted $\\mathtt{RS}$)\n",
    "\n",
    "Importantly, we do not account for the storage cost of the Zeth contracts (one time operation carried out at initialization time) and their various storage **constants** (i.e. constant protocol parameters) etc.\n",
    "\n",
    "### Blockchain state\n",
    "\n",
    "We assume that the blockchain state ($\\zeta_b$) is *only* made of:\n",
    "- The chain of block headers\n",
    "- The chain of block bodies (the set of transactions)\n",
    "- The chain of receipts (past transaction results and contract logs)\n",
    "\n",
    "### Further assumptions\n",
    "\n",
    "*Some of these assumptions are not strictly necessary, but that's helpful to make them for now, to further simplify the system and remove any potential unexpected moving pieces*\n",
    "\n",
    "1. We assume that all transactions emitted are eventually mined. More precisely, we assume:\n",
    "    - no network failures (no messages are dropped/lost)\n",
    "    - miners have unbounded memory (no need to drop transactions from the pool)\n",
    "    - miners mine transactions in the order they receive them (no censorship etc)\n",
    "2. We only consider two types of blockchain transactions:\n",
    "    - plain \"EOA-to-EOA\" transactions with no extra `data`\n",
    "    - Zeth transactions\n",
    "3. We assume the number of accounts is fixed throughout the simulation (for now we simply reason in term of number of transactions, without bothering about the account from which they come from).\n",
    "4. We model the blockchain as a mere chain of blocks (no forks, no ommer blocks etc) that are made of a header and a list of transactions.\n",
    "5. We assume that all blockchain related configuration parameters are fixed (fixed block gas limit etc.)\n",
    "6. We assume that all Zeth contracts are already deployed (no deployment cost (size/storage-wise and gas-wise) to take into consideration).\n",
    "7. We assume that the blockchain state is stored by the client in a database which supports automatic data compression:\n",
    "    - We assume that compression is instantaneous\n",
    "    - We assume a fixed compression ratio on the stored state as plain text data\n",
    "    - We ignore the potential overhead associated with accessing values associated with hashes on disk\n",
    "    - We assume that the state fits entirely in memory\n",
    "\n",
    "<u>Note:</u> At the time of writing, the [go-ethereum](https://github.com/ethereum/go-ethereum) client uses the [LevelDB database](https://github.com/google/leveldb) which compresses with [Snappy](https://github.com/google/snappy). Other databases may be used by other clients however. For instance, the [openethereum client](https://github.com/openethereum/openethereum/blob/v3.2.0/bin/oe/db/rocksdb/mod.rs) uses [Rocksdb](https://rocksdb.org/docs/getting-started.html) which compression can be further configured to use [lz4](https://github.com/lz4/lz4) for instance (though [Snappy is kept as default](https://github.com/facebook/rocksdb/wiki/Compression)). See also the documentation of [Turbo-Geth](https://github.com/ledgerwatch/turbo-geth/blob/v2021.02.04/docs/programmers_guide/db_walkthrough.MD) which proposes an alternative to go-ethereum to organise the persistent data in its database.\n",
    "\n",
    "### Constants\n",
    "\n",
    "Below are the parameters that remain constant across simulations.\n",
    "\n",
    "- The size (in bytes) of a plain Ethereum transaction is denoted by $\\mathtt{ETHTXSIZE}$\n",
    "- The intrinsic/default gas cost of an Ethereum transaction (\"plain EOA to EOA\" transaction) is denoted by $\\mathtt{DGAS}$\n",
    "- The gas cost for the set of supported pre-compiled contracts is denoted by $\\mathtt{PRECOMPILED\\_CURVES}$\n",
    "- The database compression ratio is denoted by $\\mathtt{COMPRESSION\\_RATIO}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-conspiracy",
   "metadata": {},
   "source": [
    "### Variable parameters\n",
    "\n",
    "Below are the parameters that may change across (and during) simulations.\n",
    "\n",
    "#### Zeth parameters\n",
    "\n",
    "- We denote the curve used by Zeth as $\\mathtt{ZETHCRV} \\in \\{\\mathtt{BN254}, \\mathtt{BLS12-377}\\}$ (will determine which precompiled sets we need to use to do the Zeth state transition (proof verification), which will educate on the expansiveness of the state transition)\n",
    "- Merkle tree depth $\\mathtt{MDEPTH}$ (i.e. |$\\mathtt{MKLS}| \\leq 2^\\mathtt{MDEPTH}$)\n",
    "- The number of Zeth input notes $\\mathtt{JSIN}$\n",
    "- The number of Zeth output notes $\\mathtt{JSOUT}$\n",
    "- The size (in bytes) of the Zeth Mix transaction is denoted by $\\mathtt{ZETHTXSIZE}$.\n",
    "- The number of Zeth Mix inputs is denoted by $\\mathtt{ZETHINPSIZE} = 1 + \\mathtt{JSOUT} + \\mathtt{JSIN} + 1 + \\mathtt{JSIN} + 1$ (MK root + JSOUT commitments + JSIN nullifiers + h_sig + JSIN h_i tags + residual_bits)\n",
    "- The gas cost of a Zeth Mix call is denoted by $\\mathtt{ZETHGCOST}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-healing",
   "metadata": {},
   "source": [
    "#### Blockchain parameters\n",
    "\n",
    "- We denote the blockchain by $\\mathcal{B}$ and see it as a mere chain of blocks\n",
    "- We denote the block gas limit as $\\mathtt{BGLIM}$ (important to know how many Zeth transactions can fit into a block)\n",
    "    - **TODO:** Consider treating $\\mathtt{BGLIM}$ as an \"elastic\" param/variable (instead of a constant) as in EIP1559.\n",
    "- We denote the block production time target as $\\mathtt{BTIMETRGT}$\n",
    "- (Optional) We denote the block production time lag $\\mathtt{BTIMELAG}$ (randomly selected in a time window to account for potential delays due to PoW and/or due to network latency in block propagation)\n",
    "    - For now, $\\mathtt{BTIMELAG} = 0$\n",
    "    - **TODO:** Consider adding a randomized block production lag in future iterations of the model in order to use Monte Carlo executions.\n",
    "- We denote the block production time as $\\mathtt{BTIME} = \\mathtt{BTIMETRGT} + \\mathtt{BTIMELAG}$\n",
    "- The size (in bytes) of a block is denoted by $\\mathtt{BLKSIZE}$\n",
    "\n",
    "### Initial state\n",
    "\n",
    "These are the constants initialization values that do not vary across executions\n",
    "\n",
    "- $\\mathtt{MKLS} = \\emptyset$\n",
    "- $\\mathtt{NS} = \\emptyset$\n",
    "- $\\mathtt{RS} = \\emptyset$\n",
    "- $\\mathcal{B}$ = $\\mathcal{B}_{genesis}$ (The chain is instantiated, an empty genesis block is mined)\n",
    "\n",
    "### State transition\n",
    "\n",
    "Each Zeth transaction mined adds:\n",
    "- $\\mathtt{JSOUT}$ leaves to the set $\\mathtt{MKLS}$\n",
    "- $\\mathtt{JSIN}$ nullifiers to the set $\\mathtt{NS}$\n",
    "- $\\mathtt{JSIN}$ roots to the set $\\mathtt{RS}$\n",
    "- $\\lfloor \\frac{\\mathtt{BGLIM}}{\\mathtt{ZETHGCOST}} \\rfloor$ new transactions to the blockchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-australia",
   "metadata": {},
   "source": [
    "## Modeling Zeth with different protocol parameters\n",
    "\n",
    "We first start by tracking the blockchain state growth when only plain \"EoA-to-EoA\" transactions are carried out. Then, we model Zeth with different protocol parameters to see how the blockchain state size grows under different conditions, as well as track the rate at which the Merkle tree of Zeth notes commitments is filled.\n",
    "\n",
    "We use A/B testing and \"Parameters Sweep\" simulations to study the state growth under different blockchain configurations (block gas limit etc.) and Zeth configurations (Merkle tree depth, JSIN/JSOUT etc.):\n",
    "- **Simulation A:** Only \"plain\" (with no extra `data`) EoA-to-EoA transactions are mined. This simulation uses \"Parameters Sweep\" to simulate the system under various blockchain configurations.\n",
    "- **Simulation B:** Only Zeth transactions are mined. This simulation uses \"Parameters Sweep\" to simulate the system under various blockchain configurations. The Zeth configuration tested is:\n",
    "    - Merkle tree depth = 32\n",
    "    - JSIN = JSOUT = 2\n",
    "    - Curve = BN254\n",
    "- **Simulation C:** Only Zeth transactions are mined. This simulation uses \"Parameters Sweep\" to simulate the system under various blockchain configurations. The Zeth configuration tested is:\n",
    "    - Merkle tree depth = 32\n",
    "    - JSIN = JSOUT = 2\n",
    "    - Curve = BLS12_377\n",
    "    \n",
    "All these simulations are deterministic (no MC runs) and **represent 24h worth of data**. Since no random runs are employed, the simulation results can be cached into a file to avoid multiple (expensive) runs of the model's simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-ceramic",
   "metadata": {},
   "source": [
    "### Simulation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certain-pressure",
   "metadata": {},
   "source": [
    "Before pursuing with the simulation, it is worth clarifying how the input dataset has been obtained.\n",
    "\n",
    "Ideally, in order to determine the gas cost of a state transition, one may want to use the blockchain network's gas table along with the set of opcodes defining the state transition in order to come up with a deterministic formula that computes the cost of the smart-contract call. However, such approach is not sufficient to properly determine the cost of a state transition, since several opcodes (such as `SSTORE`) have different costs depending on the smart-contract's state (i.e. depending if empty storage slots are initiliazed or simply re-written).\n",
    "As a consequence, and to ease the process, the following data (transactions gas cost and byte-size) are obtained via empirical experiments, during which a set of transactions are fired on a test network. The results below are obtained via the arithmetic mean of a simulation's results.\n",
    "Importantly, certain Zeth configurations (i.e. certain curve selections: `BLS12_377` and `BW6_761`) necessitate extensions to the EVM in order to support curve operations (point addition, scalar multiplication) and pairings for remarkable pairing groups. As such, Zeth related simulations have been carried out on an [extended version of ganache-cli](https://github.com/clearmatics/ganache-cli).\n",
    "\n",
    "We use some Ethereum mainnet data as basis to determine values for the blockchain-related variables and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of a \"standard\" raw (i.e. rlp encoded) EoA-to-EoA transaction (in bytes)\n",
    "# Here, we assume that no extra `data` is set in the transaction. We obtain this value\n",
    "# by taking the arithmetic mean of the size of a few \"plain\" EoA-to-EoA transactions\n",
    "# (i.e. without additional `data`).\n",
    "ETHTXSIZE = 111\n",
    "\n",
    "# See https://github.com/ethereum/go-ethereum/blob/v1.10.1/core/types/receipt.go#L48\n",
    "# and\n",
    "# https://github.com/ethereum/go-ethereum/blob/v1.10.1/core/types/receipt.go#L92-L97\n",
    "# Receipts for succesful EoA-to-EoA transactions will be of the form:\n",
    "# [\"0x5208520852085208\",[],\"0x1\"], leading to RLP encodings of the form:\n",
    "# 0xcb885208520852085208c001, which are 12 bytes long.\n",
    "ETH_RECEIPT_SIZE = 12\n",
    "\n",
    "# Approximate size of an Ethereum block header (in bytes)\n",
    "# See: https://ethereum.github.io/yellowpaper/paper.pdf and\n",
    "# https://github.com/ethereum/go-ethereum/blob/v1.10.1/core/types/bloom9.go#L32-L38\n",
    "# for reference\n",
    "BLOCKHEADERSIZE = 508 # 32 + 32 + 20 + 32 + 32 + 32 + 256 + 32 + 32 + 8\n",
    "\n",
    "# Intrinsic gas cost of a transaction\n",
    "DGAS = 21000\n",
    "\n",
    "# Compression ratio for Snappy on the chain state\n",
    "# See: https://github.com/google/snappy#performance\n",
    "COMPRESSION_RATIO = 1.5\n",
    "\n",
    "# The block gas limit and block time below are obtained as the median\n",
    "# of the \"Value\" column from the following datasets provided by Etherscan.io:\n",
    "# - https://etherscan.io/chart/blocktime (exported on 11/03/2021 into a file named `export-BlockTime.csv`)\n",
    "# - https://etherscan.io/chart/gaslimit (exported on 11/03/2021 into a file named `export-GasLimit.csv`)\n",
    "# More precisely, the values were obtained by running the following commands:\n",
    "# ```python\n",
    "# csv_result = pd.read_csv('export-GasLimit.csv')\n",
    "# MEDIAN_BLOCKGASLIMIT = math.ceil(csv_result[\"Value\"].median())\n",
    "#\n",
    "# csv_result = pd.read_csv('export-BlockTime.csv')\n",
    "# MEDIAN_BLOCKTIME = math.ceil(csv_result[\"Value\"].median())\n",
    "# ```\n",
    "MAINNET_MEDIAN_BLOCKGASLIMIT = 7996822\n",
    "MAINNET_MEDIAN_BLOCKTIME = 15\n",
    "\n",
    "PRECOMPILED_CURVES = {}\n",
    "# See Ethereum Istanbul gas table:\n",
    "# https://github.com/ethereum/go-ethereum/blob/master/params/protocol_params.go\n",
    "PRECOMPILED_CURVES['BN254'] = {'ECADDCOST': 150, 'ECMULCOST': 6000, 'ECPAIRBASECOST': 45000, 'ECPAIRPERPOINTCOST': 34000}\n",
    "# Gas table extension obtained during the early Zecale simulations (June 2020).\n",
    "# WARNING: The values of the parameters below need to be refined (new software benchmarks need to be carried out.)\n",
    "PRECOMPILED_CURVES['BLS12_377'] = {'ECADDCOST': 300, 'ECMULCOST': 12000, 'ECPAIRBASECOST': 90000, 'ECPAIRPERPOINTCOST': 68000}\n",
    "\n",
    "pprint(PRECOMPILED_CURVES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "# Benchmark dataset     #\n",
    "#########################\n",
    "\n",
    "# Data obtained via the `singleton_deterministic_agent.sh` Zeth script\n",
    "# ran under different Zeth configurations. The data used below is obtained\n",
    "# as the arithmetic mean of all the transactions fired by the bot script above\n",
    "# on a local testnet (and on the Autonity Bakerloo Testnet).\n",
    "\n",
    "# Note: In order to have a more flexible set of simulation scripts to use against\n",
    "# our local test network (without additional tooling), it is desirable for the issue\n",
    "# https://github.com/trufflesuite/ganache-core/issues/135\n",
    "# to be tackled and integrated into clearmatics/ganache-cli.\n",
    "# (`eth_getRawTransactionByHash` is already available in Geth and Autonity).\n",
    "\n",
    "#########\n",
    "# TODO: #\n",
    "#########\n",
    "#\n",
    "# - Consider moving this to an external CSV file that we load here.\n",
    "# - Gather mode data points for the various settings of interest AND/OR\n",
    "# consider computing some of these data points as part of the model\n",
    "# from the system's parameters (e.g. gas cost/size of txs etc.)\n",
    "#########\n",
    "\n",
    "# - The documented sizes are the sizes (in bytes) of the Zeth JSON transaction objects.\n",
    "#metrics_df = pd.DataFrame(\n",
    "#    [\n",
    "#        [\"BN254\", 32, 2, 2, 3090, 1315520],\n",
    "#        [\"BLS12_377\", 32, 2, 2, 3603, 1353261]\n",
    "#        # Switch JSOUT to 3 (e.g. to pay a Relay with an output note)\n",
    "#        #[\"BN254\", 32, 2, 3, XX, XX], # TODO\n",
    "#        #[\"BLS12_377\", 32, 2, 3, XX, XX] # TODO\n",
    "#    ],\n",
    "#    columns=['curve', 'mk_depth', 'jsin', 'jsout', 'zeth_tx_size', 'zeth_tx_gcost']\n",
    "#)\n",
    "\n",
    "# Approximate size (in bytes) for RLP encoded Zeth transaction receipt\n",
    "# Follows the specified storage encoding of a receipt\n",
    "# https://github.com/ethereum/go-ethereum/blob/v1.10.1/core/types/receipt.go#L92-L97\n",
    "#\n",
    "# This value has been obtained by:\n",
    "# 1. Inspecting Zeth transaction receipts, such as:\n",
    "# {\n",
    "#   \"blockHash\":\"0xa1ca015b7b7472f6a4a649890fb8d6cd7a85955e03e3d1b8603b2fa819c14071\",\n",
    "#   \"blockNumber\":\"0x56b73\",\n",
    "#   \"contractAddress\":null,\n",
    "#   \"cumulativeGasUsed\":\"0x1b2cd3\",\n",
    "#   \"from\":\"0xee0c66a2c570b0331c5bb1991124ed0529d11c4f\",\n",
    "#   \"gasUsed\":\"0x1b2cd3\",\n",
    "#   \"logs\":[\n",
    "#     {\n",
    "#       \"address\":\"0x26895344ba95f7a9762a5a4f871b5d5202115039\",\n",
    "#       \"topics\":[\n",
    "#         \"0x36ed7c3f2ecfb5a5226c478b034d33144c060afe361be291e948f861dcddc618\"\n",
    "#       ],\n",
    "#       \"data\":\"0x14ce028fa1e1df2d8c3b298a0659da99ae576eabd78e50607180755382193d2091f11ae060b100db666d01db0e8ab71b423192d9a1a7e75363af0ce5444ea1f96f8d3a4610c44a20545020204f0b19623b1abbb1784eb87c101ae398da0378351786c6efd30b72af6e1d7f875a8351872a4657dacb778b186d8a93e914df34490c3badefa35ee7b3a27f1b191c66bf9c066c8199452ed8f5c5f747f0997f627700000000000000000000000000000000000000000000000000000000000000c0000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000098ebf17ba5c8801a93c71f110a2a000f952fe24d018991295ae4c1b384b29dcd662cca2d57afc4c57dadcc1304122888ba13b6531cdc0afd4bb48bac8011d4c1c01bf04f27920e50b1792b6a6713644412c28b52b7f9142bd2d9dd59297fd7a546e4511b32f0d3eb3cbf19fd65374d0a55cd171b4b2d5b342802ab2788e91b5837087db3d0944f45ec011ba6b9723bbc24bf98f8ee1b732750000000000000000000000000000000000000000000000000000000000000000000000000000000981c1743cfcd668e4683946881b81ba9a69f79bcc87a5176df49c19aebfbf33d7d789be4f6de07bf66375aa208f5954a2cc41e0137e5a07239f97944e6f982493cb127c977091738c687532c7e3548394194ffa448b7e59b1222ae9d4bd9d969a6cf53b501be95300bb7b4a21bad83ffc33bc4140108d458f9b07847e7e7b3f38f27439322754d4a54e976549b40b8b10dab0a8d5ce89689050000000000000000\",\n",
    "#       \"blockNumber\":\"0x56b73\",\n",
    "#       \"transactionHash\":\"0xb4e683d7bbf4709fe7eb59fcd9041b1b90ab36266790a224d47ef894f0afa703\",\n",
    "#       \"transactionIndex\":\"0x0\",\n",
    "#       \"blockHash\":\"0xa1ca015b7b7472f6a4a649890fb8d6cd7a85955e03e3d1b8603b2fa819c14071\",\n",
    "#       \"logIndex\":\"0x0\",\n",
    "#       \"removed\":false\n",
    "#     }\n",
    "#   ],\n",
    "#   \"logsBloom\":\"0x00000000000000400000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000800000000000000000000000000000000000000000000000800000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000\",\n",
    "#   \"status\":\"0x1\",\n",
    "#   \"to\":\"0x26895344ba95f7a9762a5a4f871b5d5202115039\",\n",
    "#   \"transactionHash\":\"0xb4e683d7bbf4709fe7eb59fcd9041b1b90ab36266790a224d47ef894f0afa703\",\n",
    "#   \"transactionIndex\":\"0x0\"\n",
    "# }\n",
    "#\n",
    "# 2. Following the structure of the storage encoding of a receipt\n",
    "# https://github.com/ethereum/go-ethereum/blob/v1.10.1/core/types/receipt.go#L92-L97\n",
    "# and removing redundant fields from the JSON receipt, to obtain something like:\n",
    "# [\"0x1b2cd3\", [\"0x26895344ba95f7a9762a5a4f871b5d5202115039\",[\"0x36ed7c3f2ecfb5a5226c478b034d33144c060afe361be291e948f861dcddc618\"],\"0x14ce028fa1e1df2d8c3b298a0659da99ae576eabd78e50607180755382193d2091f11ae060b100db666d01db0e8ab71b423192d9a1a7e75363af0ce5444ea1f96f8d3a4610c44a20545020204f0b19623b1abbb1784eb87c101ae398da0378351786c6efd30b72af6e1d7f875a8351872a4657dacb778b186d8a93e914df34490c3badefa35ee7b3a27f1b191c66bf9c066c8199452ed8f5c5f747f0997f627700000000000000000000000000000000000000000000000000000000000000c0000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000098ebf17ba5c8801a93c71f110a2a000f952fe24d018991295ae4c1b384b29dcd662cca2d57afc4c57dadcc1304122888ba13b6531cdc0afd4bb48bac8011d4c1c01bf04f27920e50b1792b6a6713644412c28b52b7f9142bd2d9dd59297fd7a546e4511b32f0d3eb3cbf19fd65374d0a55cd171b4b2d5b342802ab2788e91b5837087db3d0944f45ec011ba6b9723bbc24bf98f8ee1b732750000000000000000000000000000000000000000000000000000000000000000000000000000000981c1743cfcd668e4683946881b81ba9a69f79bcc87a5176df49c19aebfbf33d7d789be4f6de07bf66375aa208f5954a2cc41e0137e5a07239f97944e6f982493cb127c977091738c687532c7e3548394194ffa448b7e59b1222ae9d4bd9d969a6cf53b501be95300bb7b4a21bad83ffc33bc4140108d458f9b07847e7e7b3f38f27439322754d4a54e976549b40b8b10dab0a8d5ce89689050000000000000000\",\"0x56b73\",\"0xb4e683d7bbf4709fe7eb59fcd9041b1b90ab36266790a224d47ef894f0afa703\",\"0x0\",\"0xa1ca015b7b7472f6a4a649890fb8d6cd7a85955e03e3d1b8603b2fa819c14071\",\"0x0\",\"0x0\"],\"0x1\"]\n",
    "# \n",
    "# 3. which can then be RLP encoded into something like:\n",
    "# \"0xf9030b831b2cd3f903039426895344ba95f7a9762a5a4f871b5d5202115039e1a036ed7c3f2ecfb5a5226c478b034d33144c060afe361be291e948f861dcddc618b9028014ce028fa1e1df2d8c3b298a0659da99ae576eabd78e50607180755382193d2091f11ae060b100db666d01db0e8ab71b423192d9a1a7e75363af0ce5444ea1f96f8d3a4610c44a20545020204f0b19623b1abbb1784eb87c101ae398da0378351786c6efd30b72af6e1d7f875a8351872a4657dacb778b186d8a93e914df34490c3badefa35ee7b3a27f1b191c66bf9c066c8199452ed8f5c5f747f0997f627700000000000000000000000000000000000000000000000000000000000000c0000000000000000000000000000000000000000000000000000000000000004000000000000000000000000000000000000000000000000000000000000001000000000000000000000000000000000000000000000000000000000000000098ebf17ba5c8801a93c71f110a2a000f952fe24d018991295ae4c1b384b29dcd662cca2d57afc4c57dadcc1304122888ba13b6531cdc0afd4bb48bac8011d4c1c01bf04f27920e50b1792b6a6713644412c28b52b7f9142bd2d9dd59297fd7a546e4511b32f0d3eb3cbf19fd65374d0a55cd171b4b2d5b342802ab2788e91b5837087db3d0944f45ec011ba6b9723bbc24bf98f8ee1b732750000000000000000000000000000000000000000000000000000000000000000000000000000000981c1743cfcd668e4683946881b81ba9a69f79bcc87a5176df49c19aebfbf33d7d789be4f6de07bf66375aa208f5954a2cc41e0137e5a07239f97944e6f982493cb127c977091738c687532c7e3548394194ffa448b7e59b1222ae9d4bd9d969a6cf53b501be95300bb7b4a21bad83ffc33bc4140108d458f9b07847e7e7b3f38f27439322754d4a54e976549b40b8b10dab0a8d5ce8968905000000000000000083056b73a0b4e683d7bbf4709fe7eb59fcd9041b1b90ab36266790a224d47ef894f0afa70300a0a1ca015b7b7472f6a4a649890fb8d6cd7a85955e03e3d1b8603b2fa819c14071000001\"\n",
    "#\n",
    "# TODO: Add the receipt size to the metrics_df below (as it depends on the config, most notably on the JSOUT)\n",
    "ZETH_RECEIPT_SIZE = 785\n",
    "\n",
    "# - The documented sizes are the sizes (in bytes) of the Zeth RAW (RLP encoded) transaction objects.\n",
    "metrics_df = pd.DataFrame(\n",
    "    [\n",
    "        [\"BN254\", 32, 2, 2, 1335, 1315520],\n",
    "        [\"BLS12_377\", 32, 2, 2, 1557, 1353261] # (approx. obtained as 3603/3090 * 1335)\n",
    "        # Switch JSOUT to 3 (e.g. to pay a Relay with an output note)\n",
    "        #[\"BN254\", 32, 2, 3, XX, XX], # TODO\n",
    "        #[\"BLS12_377\", 32, 2, 3, XX, XX] # TODO\n",
    "    ],\n",
    "    columns=['curve', 'mk_depth', 'jsin', 'jsout', 'zeth_tx_size', 'zeth_tx_gcost']\n",
    ")\n",
    "\n",
    "\n",
    "def get_benchmark_data(curve, mk_depth, jsin, jsout):\n",
    "    \"\"\"\n",
    "    Function that queries the benchmark dataset to retrieve the data points\n",
    "    relevant to the given model configuration.\n",
    "    \"\"\"\n",
    "    result_df = metrics_df.query(\n",
    "        'curve == @curve and\\\n",
    "        mk_depth == @mk_depth and\\\n",
    "        jsin == @jsin and\\\n",
    "        jsout == @jsout'\n",
    "    )\n",
    "    # Assert that the retrieved df has only 1 line\n",
    "    # (to avoid data inconsistency on duplicated lines)\n",
    "    assert result_df.shape[0] == 1, \"[ERROR] Wrong number of data points in benchmark data\"\n",
    "    \n",
    "    zeth_tx_size = result_df.iloc[0]['zeth_tx_size']\n",
    "    zeth_tx_gcost = result_df.iloc[0]['zeth_tx_gcost']\n",
    "    return (zeth_tx_size, zeth_tx_gcost)\n",
    "\n",
    "# Test the query function\n",
    "size, gas = get_benchmark_data(\"BN254\", 32, 2, 2)\n",
    "print(\"Result size: {} and gas: {}\".format(size, gas))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-hamilton",
   "metadata": {},
   "source": [
    "### Genesis state of the simulation(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################\n",
    "# State variables             #\n",
    "###############################\n",
    "\n",
    "# Genesis state: the same is used for both A/B testing simulations\n",
    "genesis_state = {\n",
    "    # All sets are initialized with the empty set (they have no elements)\n",
    "    'MKLS_cardinality': 0,\n",
    "    'NS_cardinality': 0,\n",
    "    'RS_cardinality': 0,\n",
    "    # The size of the blockchain is assumed to be 0 at starting time\n",
    "    'B_size': 0,\n",
    "    'B_txcount': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-kelly",
   "metadata": {},
   "source": [
    "### System parameters of the simulation\n",
    "\n",
    "The set of parameters (of interest) used for the A/B(/C) testing and \"Parameter Sweep\" simulation of Zeth is defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Simulation configuration   #\n",
    "##############################\n",
    "\n",
    "# Array of params used during the \"Parameter Sweeps\" Simulation\n",
    "# to simulate under different blockchain configuration assumptions.\n",
    "BLOCKCHAIN_PARAMS = [\n",
    "    # Arbitrary set of blockchain config params\n",
    "    # (from big blocks mined \"slowly\" to smaller blocks mined \"frequently\")\n",
    "    { 'bglim': 25000000, 'btimetrgt': 15 },\n",
    "    { 'bglim': 12500000, 'btimetrgt': 5 },\n",
    "    { 'bglim': 5000000, 'btimetrgt': 1 },\n",
    "    # Ethereum mainnet median data\n",
    "    { 'bglim': MAINNET_MEDIAN_BLOCKGASLIMIT, 'btimetrgt': MAINNET_MEDIAN_BLOCKTIME }\n",
    "]\n",
    "\n",
    "# Simulate a system where only plain \"EoA-to-EoA\" transactions are\n",
    "# carried out (no smart contract deployed)\n",
    "system_params_A = {\n",
    "    'chain' : BLOCKCHAIN_PARAMS,\n",
    "}\n",
    "\n",
    "# Below, we simulate different Zeth configurations (using different curves)\n",
    "# on different blockchain configurations.\n",
    "system_params_B = {\n",
    "    'chain' : BLOCKCHAIN_PARAMS,\n",
    "    'zeth' : [\n",
    "        # Test all the blockchain configs with this Zeth config\n",
    "        { 'curve': \"BN254\", 'mkdepth': 32, 'jsin': 2, 'jsout': 2 },\n",
    "    ]\n",
    "}\n",
    "\n",
    "system_params_C = {\n",
    "    'chain' : BLOCKCHAIN_PARAMS,\n",
    "    'zeth' : [\n",
    "        # Test all the blockchain configs with this Zeth config\n",
    "        { 'curve': \"BLS12_377\", 'mkdepth': 32, 'jsin': 2, 'jsout': 2 },\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-necklace",
   "metadata": {},
   "source": [
    "### Policy functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Policy functions          #\n",
    "#############################\n",
    "#\n",
    "# Manage time on the system\n",
    "#\n",
    "# We need to simulate the various block time targets\n",
    "# If btimetrgt = 1, a block is added a each time step\n",
    "# If btimetrgt = 5, a block is added every 5 time steps\n",
    "# If btimetrgt = 15, a block is added every 15 time steps\n",
    "def p_is_add_block(params, substep, state_history, previous_state):\n",
    "    \"\"\"\n",
    "    Function that determines whether we need to mine a block at this time step or not\n",
    "    \"\"\"\n",
    "    # At t = 0, this condition will be true for all block intervals\n",
    "    # hence, producing the genesis block\n",
    "    if previous_state['timestep'] % params['chain']['btimetrgt'] == 0:\n",
    "        return ({'add_block': True})\n",
    "    return ({'add_block': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-council",
   "metadata": {},
   "source": [
    "#### Policy functions (simulation A: EoA-to-EoA transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-momentum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the block size (bytes) for Ethereum (EoA-to-EoA) only txs\n",
    "def p_get_ethereum_block_size_bytes(params, substep, state_history, previous_state):\n",
    "    nb_txs = params['chain']['bglim'] // DGAS\n",
    "    # Account for the snappy compression in the state DB\n",
    "    block_size = (nb_txs * ETHTXSIZE + BLOCKHEADERSIZE + ETH_RECEIPT_SIZE) / COMPRESSION_RATIO\n",
    "    return ({'block_size': block_size, 'number_txs': nb_txs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lonely-cancellation",
   "metadata": {},
   "source": [
    "#### Policy functions (simulation B/C: Zeth transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the block size (bytes) for Zeth only txs\n",
    "# - Returns the block size and the number of txs in the block\n",
    "def p_get_zeth_block_size_bytes(params, substep, state_history, previous_state):\n",
    "    # Retrieve Zeth benchmark data\n",
    "    curve = params['zeth']['curve']\n",
    "    mkdepth = params['zeth']['mkdepth']\n",
    "    jsin = params['zeth']['jsin']\n",
    "    jsout = params['zeth']['jsout']\n",
    "    zeth_tx_size, zeth_tx_gas = get_benchmark_data(curve, mkdepth, jsin, jsout)\n",
    "    \n",
    "    nb_txs = params['chain']['bglim'] // zeth_tx_gas\n",
    "    # Account for the snappy compression in the state DB\n",
    "    block_size = (nb_txs * zeth_tx_size + BLOCKHEADERSIZE + ZETH_RECEIPT_SIZE) / COMPRESSION_RATIO\n",
    "    return ({'block_size': block_size, 'number_txs': nb_txs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-latter",
   "metadata": {},
   "source": [
    "### State update functions (SUFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "# Simple state update functions #\n",
    "#################################\n",
    "#\n",
    "# - `params`: Python dictionary containing the system parameters\n",
    "# - `substep`: Integer value representing a step within a single timestep\n",
    "# - `state_history`: Python list of all previous states\n",
    "# - `previous_state`: Python dictionary that defines what the state of the system was at the previous timestep or substep\n",
    "# - `policy_input`: Python dictionary of signals or actions from policy functions\n",
    "\n",
    "def s_update_B_size(params, substep, state_history, previous_state, policy_input):\n",
    "    \"\"\"\n",
    "    Update the size of the blockchain B\n",
    "    \"\"\"\n",
    "    new_value = previous_state['B_size'] + policy_input['add_block'] * policy_input['block_size']\n",
    "    return 'B_size', new_value\n",
    "\n",
    "def s_update_B_txcount(params, substep, state_history, previous_state, policy_input):\n",
    "    \"\"\"\n",
    "    Update the size of the blockchain B\n",
    "    \"\"\"\n",
    "    new_value = previous_state['B_txcount'] + policy_input['add_block'] * policy_input['number_txs']\n",
    "    return 'B_txcount', new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-security",
   "metadata": {},
   "source": [
    "#### SUFs (simulation A: EoA-to-EoA transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# None are specific to simulation A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-consultation",
   "metadata": {},
   "source": [
    "#### SUFs (simulation B/C: Zeth transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_update_MKLS_cardinality(params, substep, state_history, previous_state, policy_input):\n",
    "    \"\"\"\n",
    "    Update the cardinality of the set MKLS\n",
    "    \"\"\"\n",
    "    new_value = previous_state['MKLS_cardinality'] + policy_input['add_block'] * policy_input['number_txs'] * params['zeth']['jsout']\n",
    "    return 'MKLS_cardinality', new_value\n",
    "\n",
    "def s_update_NS_cardinality(params, substep, state_history, previous_state, policy_input):\n",
    "    \"\"\"\n",
    "    Update the cardinality of the set NS\n",
    "    \"\"\"\n",
    "    new_value = previous_state['NS_cardinality'] + policy_input['add_block'] * policy_input['number_txs'] * params['zeth']['jsin']\n",
    "    return 'NS_cardinality', new_value\n",
    "\n",
    "def s_update_RS_cardinality(params, substep, state_history, previous_state, policy_input):\n",
    "    \"\"\"\n",
    "    Update the cardinality of the set RS\n",
    "    \"\"\"\n",
    "    new_value = previous_state['RS_cardinality'] + policy_input['add_block'] * policy_input['number_txs'] * params['zeth']['jsin']\n",
    "    return 'RS_cardinality', new_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-microphone",
   "metadata": {},
   "source": [
    "### Partial State Update Blocks (PSUBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-communication",
   "metadata": {},
   "source": [
    "#### PSUBs (simulation A: EoA-to-EoA transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-ivory",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_state_update_blocks_A = [\n",
    "    { \n",
    "        'policies': {\n",
    "            'is_add_block': p_is_add_block,\n",
    "            'get_ethereum_block_size_bytes': p_get_ethereum_block_size_bytes\n",
    "        },\n",
    "        # Update all these variables in parallel\n",
    "        'variables': {\n",
    "            'B_size': s_update_B_size,\n",
    "            'B_txcount': s_update_B_txcount\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-touch",
   "metadata": {},
   "source": [
    "#### PSUBs (simulation B/C: Zeth transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-federal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partial State Update Block shared by both simulation B and simulation C\n",
    "partial_state_update_blocks_B_and_C = [\n",
    "    { \n",
    "        'policies': {\n",
    "            'is_add_block': p_is_add_block,\n",
    "            'get_zeth_block_size_bytes': p_get_zeth_block_size_bytes\n",
    "        },\n",
    "        # Update all these variables in parallel\n",
    "        'variables': {\n",
    "            'MKLS_cardinality': s_update_MKLS_cardinality,\n",
    "            'NS_cardinality': s_update_NS_cardinality,\n",
    "            'RS_cardinality': s_update_RS_cardinality,\n",
    "            'B_size': s_update_B_size,\n",
    "            'B_txcount': s_update_B_txcount\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-youth",
   "metadata": {},
   "source": [
    "### Simulation configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For multiple MC runs, we can use the state['run'] variable that allows to get the run number\n",
    "MONTE_CARLO_RUNS = 1\n",
    "SIMULATION_TIMESTEPS = 86400 # Number of seconds in a day: 60*60*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config_A = config_sim({\n",
    "    'N': MONTE_CARLO_RUNS,\n",
    "    'T': range(SIMULATION_TIMESTEPS),\n",
    "    'M': system_params_A\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config_B = config_sim({\n",
    "    'N': MONTE_CARLO_RUNS,\n",
    "    'T': range(SIMULATION_TIMESTEPS),\n",
    "    'M': system_params_B\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empirical-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_config_C = config_sim({\n",
    "    'N': MONTE_CARLO_RUNS,\n",
    "    'T': range(SIMULATION_TIMESTEPS),\n",
    "    'M': system_params_C\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-testament",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the configuration structure for the param sweep simulation\n",
    "def print_config_and_system_params(sim_config, system_params):\n",
    "    print('sim_config: ')\n",
    "    pprint(sim_config)\n",
    "    print('  ')\n",
    "    print('system_params: ')\n",
    "    pprint(system_params_A)\n",
    "\n",
    "print(' === Simulation A: ===\\n')\n",
    "print_config_and_system_params(sim_config_A, system_params_A)\n",
    "print('\\n=== Simulation B: ===\\n')\n",
    "print_config_and_system_params(sim_config_B, system_params_B)\n",
    "print('\\n=== Simulation C: ===\\n')\n",
    "print_config_and_system_params(sim_config_C, system_params_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-award",
   "metadata": {},
   "source": [
    "### Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-publisher",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Carry out the simulations\n",
    "\n",
    "# Clear any prior configs\n",
    "del configs[:]\n",
    "\n",
    "# Create new experiment\n",
    "experiment = Experiment()\n",
    "\n",
    "# Append Simulation A config (only EoA-to-EoA transactions hit the chain)\n",
    "experiment.append_configs(\n",
    "    initial_state = genesis_state,\n",
    "    partial_state_update_blocks = partial_state_update_blocks_A,\n",
    "    sim_configs = sim_config_A\n",
    ")\n",
    "# Append Simulation B config (only Zeth transactions hit the chain: BN254, MK depth 32, JSIN=JSOUT=2)\n",
    "experiment.append_configs(\n",
    "    initial_state = genesis_state,\n",
    "    partial_state_update_blocks = partial_state_update_blocks_B_and_C,\n",
    "    sim_configs = sim_config_B\n",
    ")\n",
    "# Append Simulation C config (only Zeth transactions hit the chain: BLS12_377, MK depth 32, JSIN=JSOUT=2)\n",
    "experiment.append_configs(\n",
    "    initial_state = genesis_state,\n",
    "    partial_state_update_blocks = partial_state_update_blocks_B_and_C,\n",
    "    sim_configs = sim_config_C\n",
    ")\n",
    "\n",
    "# Get relation between the:\n",
    "# - Simulation ID\n",
    "# - Subset ID\n",
    "# - Run ID\n",
    "# And the actual user-defined configurations.\n",
    "# This is particularly useful to better understand the simulation results in the next section of the notebook.\n",
    "for i in range(len(configs)):\n",
    "    #pprint(configs[i].__dict__)\n",
    "    print(configs[i].sim_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to use the cached simulation results by default\n",
    "CACHED_SIMULATION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-textbook",
   "metadata": {},
   "source": [
    "**If you have already carried out the simulation, cached its results, and simply want to plot the simulation results, please jump to [this step](#Load-cached-simulation-results) (and do not execute the boxes below).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this box is executed, then we run the full simulations\n",
    "# and thus won't be plotting from the cached results\n",
    "CACHED_SIMULATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-washington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation A\n",
    "exec_mode = ExecutionMode()\n",
    "exec_context = ExecutionContext(context=exec_mode.multi_mode)\n",
    "\n",
    "simulation = Executor(exec_context=exec_context, configs=configs)\n",
    "raw_result, tensor_field, sessions = simulation.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_result = pd.DataFrame(raw_result)\n",
    "simulation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marine-finnish",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tabulate import tabulate\n",
    "#print(tabulate(simulation_result, headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-bobby",
   "metadata": {},
   "source": [
    "#### Cache simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neural-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the simulation results\n",
    "compression_opts = dict(method='zip', archive_name='simulation_result.csv')\n",
    "simulation_result.to_csv('simulation_result.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-interaction",
   "metadata": {},
   "source": [
    "#### Load cached simulation results\n",
    "\n",
    "If you wish to plot the results of a past simulation (without re-running the full set of simulations above), please start here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we use cached simulation results\n",
    "if CACHED_SIMULATION:\n",
    "    print(\"Loading cached simulation results...\")\n",
    "    compression_opts = dict(method='zip', archive_name='simulation_result.csv')\n",
    "    simulation_result = pd.read_csv('simulation_result.zip', compression=compression_opts)\n",
    "    print(\"Loading completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-shakespeare",
   "metadata": {},
   "source": [
    "### Simulation data processing and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-accountability",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Copy the simulation data in a new data frame\n",
    "df = simulation_result.copy()\n",
    "df_simulation_sweep_A = df[df['simulation'] == 0]\n",
    "df_simulation_sweep_B = df[df['simulation'] == 1]\n",
    "df_simulation_sweep_C = df[df['simulation'] == 2]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-biology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Multiple plots for each `subset` (i.e. for each system configuration during the \"Param Sweep\" simulation) \n",
    "px.line(\n",
    "    df,\n",
    "    x='timestep',\n",
    "    y=['B_size'],\n",
    "    facet_row='subset', # Each row is a blockchain config (and zeth config if applicable)\n",
    "    facet_col='simulation',# Columns = Zeth txs (simulation 0), EoA-to-EoA (simulation 1)\n",
    "    color='subset',\n",
    "    title='Growth of the Blockchain state under various protocol configurations (Facets view)',\n",
    "    labels=dict(timestep=\"Timesteps (sec)\", value=\"Chain size (bytes)\", subset=\"Configuration\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-highlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple plots for each `subset` (i.e. for each system configuration during the \"Param Sweep\" simulation) \n",
    "px.line(\n",
    "    df,\n",
    "    x='timestep',\n",
    "    y=['B_size'],\n",
    "    color='subset',\n",
    "    facet_col='simulation',\n",
    "    title='Growth of the Blockchain state under various protocol configurations (Overlaid view)',\n",
    "    labels=dict(timestep=\"Timesteps (sec)\", value=\"Blockchain size (in bytes)\", subset=\"Configuration number\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can further extract the results of a specific \"sweep simulation\"\n",
    "df_simulation_zeth_A = df[df['simulation'] == 1]\n",
    "# Extract a specific sweep run (i.e. a run with a specific configuration)\n",
    "df_simulation_sweep_run = df_simulation_zeth_A[df_simulation_zeth_A['subset'] == 0]\n",
    "# Display the first timesteps of the simulation with config 0\n",
    "df_simulation_sweep_run.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Zeth simulations are simulations B and C (i.e. at index 1 and 2 in the results)\n",
    "# The simulation A (at index 0) contains the results for the EoA-to-EoA case\n",
    "df_simulation_zeth = df[df['simulation'].isin([1, 2])]\n",
    "df_simulation_zeth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-symbol",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df_simulation_zeth,\n",
    "    x='timestep',\n",
    "    y=['MKLS_cardinality'],\n",
    "    facet_row='subset',\n",
    "    facet_col='simulation',\n",
    "    color='subset',\n",
    "    title='Growth of the Merkle tree leaves set cardinality under various protocol configurations (Facets view)',\n",
    "    labels=dict(timestep=\"Timesteps (sec)\", value=\"MKLS\", subset=\"Config\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(\n",
    "    df_simulation_zeth,\n",
    "    x='timestep',\n",
    "    y=['MKLS_cardinality'],\n",
    "    facet_col='simulation',\n",
    "    color='subset',\n",
    "    title='Growth of the Merkle tree leaves set cardinality under various protocol configurations (Overlaid view)',\n",
    "    labels=dict(timestep=\"Timesteps (sec)\", value=\"Number of leaves in the Merkle tree\", subset=\"Configuration number\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "light-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of Zeth simulations\n",
    "nb_simulations = df_simulation_zeth['simulation'].nunique()\n",
    "# For now we only account for 2 zeth param sweep simulations\n",
    "# We can make the code more generic if necessary\n",
    "assert nb_simulations == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-receiver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All simulations should have the same number of subsets (should be equal to the number of parameter sweeps)\n",
    "nb_sweeps = len(BLOCKCHAIN_PARAMS)\n",
    "nb_sweeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the ratio of leaves (in the MK tree) that are allocated in a\n",
    "# simulation over the total number of leaves in the tree\n",
    "mktree_occupancy_ratios_result = {}\n",
    "# Track of the number of times the given simulation needs to be ran\n",
    "# (i.e. number of days) before the Merkle tree is completely filled.\n",
    "simulation_runs_to_mktree_occupancy_result = {}\n",
    "\n",
    "\n",
    "# Build dataset representing the % of Merkle tree occupancy rate for all \"sweeped simulations\"\n",
    "for sim_id in [1,2]:\n",
    "    # Get the specific simulation results\n",
    "    df_simulation_id = df_simulation_zeth[df_simulation_zeth['simulation'] == sim_id]\n",
    "    \n",
    "    mktree_occupancy_ratio = []\n",
    "    simulation_runs_to_mktree_occupancy = []\n",
    "    for sweep_id in range(nb_sweeps):\n",
    "        # Get the specific simulation's sweep results\n",
    "        df_sweep_id = df_simulation_id[df_simulation_id['subset'] == sweep_id]\n",
    "        config_id = nb_sweeps * sim_id + (sweep_id % nb_sweeps)\n",
    "        # Get Merkle tree depth of the associated configuration\n",
    "        mkdepth = configs[config_id].sim_config['M']['zeth']['mkdepth']\n",
    "        # Get last state of the simulation\n",
    "        final_state_simulation = df_sweep_id.tail(1)\n",
    "        # Read final cardinality of MKLS (at the end of the simulation)\n",
    "        final_mkls_cardinality = final_state_simulation.iloc[0]['MKLS_cardinality']\n",
    "        # Compute the remaining number of leaves\n",
    "        free_leaves = 2**mkdepth - final_mkls_cardinality\n",
    "        # Compute occupancy ratio\n",
    "        ratio_occupied = (final_mkls_cardinality / free_leaves) * 100\n",
    "        mktree_occupancy_ratio.append([ratio_occupied, sweep_id])\n",
    "        simulation_runs_to_mktree_occupancy.append((2**mkdepth) // final_mkls_cardinality)\n",
    "        \n",
    "    mktree_occupancy_ratios_result[sim_id] = mktree_occupancy_ratio\n",
    "    simulation_runs_to_mktree_occupancy_result[sim_id] = simulation_runs_to_mktree_occupancy\n",
    "\n",
    "pprint(mktree_occupancy_ratios_result)\n",
    "pprint(simulation_runs_to_mktree_occupancy_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-handle",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# See here for the list of available colors:\n",
    "# https://community.plotly.com/t/plotly-colours-list/11730/3\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "merkle_tree_df_zeth_A = pd.DataFrame(\n",
    "    mktree_occupancy_ratios_result[1],\n",
    "    columns=['ratio_occupied', 'subset'],\n",
    ")\n",
    "merkle_tree_df_zeth_B = pd.DataFrame(\n",
    "    mktree_occupancy_ratios_result[2],\n",
    "    columns=['ratio_occupied', 'subset'],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=merkle_tree_df_zeth_A['subset'],\n",
    "    y=merkle_tree_df_zeth_A['ratio_occupied'],\n",
    "    name='Zeth (BN254)',\n",
    "    marker_color='darkcyan'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=merkle_tree_df_zeth_B['subset'],\n",
    "    y=merkle_tree_df_zeth_B['ratio_occupied'],\n",
    "    name='Zeth (BLS12_377)',\n",
    "    marker_color='darkgray'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Occupancy rate of Merkle Tree per simulation run under various system configurations\",\n",
    "    xaxis_title=\"Various blockchain configurations\",\n",
    "    yaxis_title=\"Percentage of Merkle Tree occupancy per simulation run\",\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-housing",
   "metadata": {},
   "source": [
    "## Answers to the open questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-recognition",
   "metadata": {},
   "source": [
    "### Answer to [question 1](#Question-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-celebration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of successive/incremental simulation runs required to completely fill the Merkle Tree\n",
    "# in the different situations\n",
    "for sim_id in simulation_runs_to_mktree_occupancy_result:\n",
    "    print('=== Simulation {}: ==='.format(sim_id))\n",
    "    for i in range(len(simulation_runs_to_mktree_occupancy_result[sim_id])):\n",
    "        print(\"- Config {} needs to be ran another {} times to fill the Merkle tree\".format(i, simulation_runs_to_mktree_occupancy_result[sim_id][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-thesaurus",
   "metadata": {},
   "source": [
    "### Answer to [question 2](#Question-2) and [question 4](#Question-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 TB approx. 10**12 bytes\n",
    "terabyte = 10**12\n",
    "\n",
    "def compute_simulation_terabyte_occupancy_rate(simulation_df):\n",
    "    terabyte_occupancy_rate = []\n",
    "    nb_simulation_runs = []\n",
    "    for i in range(nb_sweeps):\n",
    "        # Get the specific simulation results\n",
    "        df_sweeped_simulation = simulation_df[simulation_df['subset'] == i]\n",
    "        # Get last state of the simulation\n",
    "        final_state_simulation = df_sweeped_simulation.tail(1)\n",
    "        final_blockchain_size = final_state_simulation.iloc[0]['B_size']\n",
    "        # Compute terabyte occupancy ratio\n",
    "        ratio_occupied = (final_blockchain_size / terabyte) * 100\n",
    "        # Append simulation results to the aggregate arrays (aggregating these metrics for all simulations)\n",
    "        terabyte_occupancy_rate.append([ratio_occupied, \"config-\"+str(i)])\n",
    "        nb_simulation_runs.append(terabyte // final_blockchain_size)\n",
    "    return (terabyte_occupancy_rate, nb_simulation_runs)\n",
    "\n",
    "\n",
    "terabyte_occupancy_rate_simulations_result = {}\n",
    "nb_simulation_runs_simulations_result = {}\n",
    "\n",
    "nb_simulations = df['simulation'].nunique()\n",
    "for sim_id in range(nb_simulations):\n",
    "    df_simulation_id = df[df['simulation'] == sim_id]\n",
    "    res_simulation_id = compute_simulation_terabyte_occupancy_rate(df_simulation_id)\n",
    "    terabyte_occupancy_rate_simulations_result[sim_id] = res_simulation_id[0]\n",
    "    nb_simulation_runs_simulations_result[sim_id] = res_simulation_id[1]\n",
    "\n",
    "\n",
    "pprint(terabyte_occupancy_rate_simulations_result)\n",
    "pprint(nb_simulation_runs_simulations_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "located-thumb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# terabyte occupancy rate after simulation\n",
    "terabyte_df_simulation_A = pd.DataFrame(\n",
    "    terabyte_occupancy_rate_simulations_result[0],\n",
    "    columns=['ratio_occupied', 'subset'],\n",
    ")\n",
    "terabyte_df_simulation_B = pd.DataFrame(\n",
    "    terabyte_occupancy_rate_simulations_result[1],\n",
    "    columns=['ratio_occupied', 'subset'],\n",
    ")\n",
    "terabyte_df_simulation_C = pd.DataFrame(\n",
    "    terabyte_occupancy_rate_simulations_result[2],\n",
    "    columns=['ratio_occupied', 'subset'],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=terabyte_df_simulation_A['subset'],\n",
    "    y=terabyte_df_simulation_A['ratio_occupied'],\n",
    "    name='EoA-to-EoA',\n",
    "    marker_color='indianred'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=terabyte_df_simulation_B['subset'],\n",
    "    y=terabyte_df_simulation_B['ratio_occupied'],\n",
    "    name='Zeth (BN254)',\n",
    "    marker_color='darkcyan'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=terabyte_df_simulation_C['subset'],\n",
    "    y=terabyte_df_simulation_C['ratio_occupied'],\n",
    "    name='Zeth (BLS12_377)',\n",
    "    marker_color='darkgray'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Occupancy rate of 1TB per simulation run under various system configurations\",\n",
    "    xaxis_title=\"Various blockchain configurations\",\n",
    "    yaxis_title=\"Percentage of occupancy of 1TB per simulation run\",\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of successive/incremental simulation runs required to completely fill the Merkle Tree\n",
    "# in the different situations\n",
    "for sim_id in nb_simulation_runs_simulations_result:\n",
    "    print('=== Simulation {}: ==='.format(sim_id))\n",
    "    for i in range(len(nb_simulation_runs_simulations_result[sim_id])):\n",
    "        print(\"- Config {} needs to be ran another {} times to fill 1TB of storage\".format(i, nb_simulation_runs_simulations_result[sim_id][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-individual",
   "metadata": {},
   "source": [
    "### Answer to [question 3](#Question-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Refactor this block\n",
    "#\n",
    "# For now we use hardcoded queries. May be worth refactoring this to\n",
    "# query the benchmark data by reading the configurations of the simulations\n",
    "# to have a more generic approach.\n",
    "zethSizeBN254, zethGasBN254 = get_benchmark_data(\"BN254\", 32, 2, 2)\n",
    "zethSizeBLS12377, zethGasBLS12377 = get_benchmark_data(\"BLS12_377\", 32, 2, 2)\n",
    "\n",
    "# Compute byte cost (in gas) of the transactions\n",
    "BYTE_COST_EOA_TO_EOA = DGAS / (ETHTXSIZE + ETH_RECEIPT_SIZE)\n",
    "byteCostZethTxBN254 = zethGasBN254/ (zethSizeBN254 + ZETH_RECEIPT_SIZE)\n",
    "byteCostZethTxBLS12377 = zethGasBLS12377 / (zethSizeBLS12377 + ZETH_RECEIPT_SIZE)\n",
    "\n",
    "# Compute the size ratio of Zeth transactions vs plain EoA-to-EoA transactions\n",
    "sizeRatioBN254 = (zethSizeBN254 + ZETH_RECEIPT_SIZE) / (ETHTXSIZE + ETH_RECEIPT_SIZE)\n",
    "sizeRatioBLS12377 = (zethSizeBLS12377 + ZETH_RECEIPT_SIZE) / (ETHTXSIZE + ETH_RECEIPT_SIZE)\n",
    "\n",
    "# Compute the cost ratio of Zeth transactions vs plain EoA-to-EoA transactions\n",
    "costRatioBN254 = zethGasBN254 / DGAS\n",
    "costRatioBLS12377 = zethGasBLS12377 / DGAS\n",
    "\n",
    "print(\" == Gas paid per byte added to the chain == \")\n",
    "print(\"Config A (EoA-to-EoA): \", BYTE_COST_EOA_TO_EOA)\n",
    "print(\"Config B (Zeth with BN254): \", byteCostZethTxBN254)\n",
    "print(\"Config C (Zeth with BLS12377): \", byteCostZethTxBLS12377)\n",
    "print(\" \")\n",
    "print(\" == Size ratios (tracks how much bigger a Zeth tx is w.r.t a plain EoA-to-EoA tx) == \")\n",
    "print(\"Config B (Zeth with BN254): \", sizeRatioBN254)\n",
    "print(\"Config C (Zeth with BLS12377): \", sizeRatioBLS12377)\n",
    "print(\" \")\n",
    "print(\" == Cost ratios (tracks how much more expensive a Zeth tx is w.r.t a plain EoA-to-EoA tx) == \")\n",
    "print(\"Config B (Zeth with BN254): \", costRatioBN254)\n",
    "print(\"Config C (Zeth with BLS12377): \", costRatioBLS12377)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-trust",
   "metadata": {},
   "source": [
    "### Answer to [question 5](#Question-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPS tracker\n",
    "# (more precisely, here we track the number of transactions per block\n",
    "# under the different configurations)\n",
    "\n",
    "def get_number_transactions_end_simulation(simulation_df):\n",
    "    nb_transactions = []\n",
    "    for i in range(nb_sweeps):\n",
    "        # Get the specific simulation results\n",
    "        df_sweeped_simulation = simulation_df[simulation_df['subset'] == i]\n",
    "        # Get last state of the simulation\n",
    "        final_state_simulation = df_sweeped_simulation.tail(1)\n",
    "        final_transaction_nb = final_state_simulation.iloc[0]['B_txcount']\n",
    "        nb_transactions.append([final_transaction_nb, \"config-\"+str(i)])\n",
    "    return nb_transactions\n",
    "\n",
    "\n",
    "nb_transactions_simulations_result = {}\n",
    "\n",
    "nb_simulations = df['simulation'].nunique()\n",
    "for sim_id in range(nb_simulations):\n",
    "    df_simulation_id = df[df['simulation'] == sim_id]\n",
    "    res_simulation_id = get_number_transactions_end_simulation(df_simulation_id)\n",
    "    nb_transactions_simulations_result[sim_id] = res_simulation_id\n",
    "\n",
    "\n",
    "pprint(nb_transactions_simulations_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of processed transactions\n",
    "nb_transactions_simulation_A = pd.DataFrame(\n",
    "    nb_transactions_simulations_result[0],\n",
    "    columns=['B_txcount', 'subset'],\n",
    ")\n",
    "nb_transactions_simulation_B = pd.DataFrame(\n",
    "    nb_transactions_simulations_result[1],\n",
    "    columns=['B_txcount', 'subset'],\n",
    ")\n",
    "nb_transactions_simulation_C = pd.DataFrame(\n",
    "    nb_transactions_simulations_result[2],\n",
    "    columns=['B_txcount', 'subset'],\n",
    ")\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(\n",
    "    x=nb_transactions_simulation_A['subset'],\n",
    "    y=nb_transactions_simulation_A['B_txcount'],\n",
    "    name='EoA-to-EoA',\n",
    "    marker_color='indianred'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=nb_transactions_simulation_B['subset'],\n",
    "    y=nb_transactions_simulation_B['B_txcount'],\n",
    "    name='Zeth (BN254)',\n",
    "    marker_color='darkcyan'\n",
    "))\n",
    "fig.add_trace(go.Bar(\n",
    "    x=nb_transactions_simulation_C['subset'],\n",
    "    y=nb_transactions_simulation_C['B_txcount'],\n",
    "    name='Zeth (BLS12_377)',\n",
    "    marker_color='darkgray'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Number of transactions processed at the end of each simulations\",\n",
    "    xaxis_title=\"Various blockchain configurations\",\n",
    "    yaxis_title=\"Number of transactions processed per simulation run\",\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-hobby",
   "metadata": {},
   "source": [
    "## Notes and Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-designer",
   "metadata": {},
   "source": [
    "###  Note 1\n",
    "\n",
    "Our results are obtained by using an *over-simplification of the real-life system* (simplifying assumptions are made - by the essence of modeling). The goal of this work is simply to get a \"taste\" on how the system evolves over time under different configurations. **Importantly however, we stress that these numbers should not be interpreted as a fully accurate and truthworthy representation of a real life system's growth.**\n",
    "\n",
    "###  Note 2\n",
    "\n",
    "The data fed into the simulations comes from different sources (some is derived from data sets provided by [Etherscan.io](https://etherscan.io/) (see [details here](#Simulation-dataset)), some come from [our BLS12-377-enabled fork of ganache](https://github.com/clearmatics/ganache-cli), some come from the [Autonity Bakerloo testnet](https://explorer.bakerloo.autonity.network/) etc). Hence, it is necessary to note that the multiple sources of data used in this work adds another layer of noise on top of the model's simplifications of the real world. Further iterations of these set of simulations will be carried out in the future with more uniform data sources and more accurate data.\n",
    "\n",
    "### Observations\n",
    "\n",
    "Overall, no surprising results here.\n",
    "\n",
    "- We see, on the various plots above summarizing the simulation results, that using Zeth does not yield a \"state blow-up\" for the mere reason that fewer transactions hit the chain. It would, of course, be foolish to say that \"Zeth is more scalable than EoA-to-EoA transactions\" however. This, in fact, is all the contrary. As expected, Zeth significantly impacts the chain state (a Zeth transaction is an order of magnitude bigger (byte-wise) than an EoA-to-EoA transaction (see boxes above)). Nevertheless, it is worth noting that the ratio of gas between Zeth and EoA-to-EoA transactions is *significantly higher* than the size ratio. This means that Zeth transactions are \"less gas-efficient\" than EoA-to-EoA transactions as you pay more gas per byte added to the state when doing such state transitions (whether or not this is good or bad depends on the context. This surely isn't really a good news for Zeth users who are paying more - byte-wise - than plain EoA-to-EoA transaction senders do. However, having \"expensive\" byte addition to the state decreases tensions around _\"state rent\"_ which is good overall for the health of the system)). This also means that significantly less Zeth transactions are included and mined into blocks, affecting the throughput/TPS of the system. Hence, to keep a similar TPS than in the EoA-to-EoA case, one needs to adjust the L1 parameters to mine bigger blocks, effectively compromising on the state growth. (This is the main motivation behind Zecale as a way to reconcile privacy preserving state transitions and scalability.)\n",
    "\n",
    "- It is worth noting that for similar configuration parameters (i.e. for fixed `JSIN`/`JSOUT`/`MK Tree depth`) the BN254 and BLS12-377 simulations provide slightly diffferent simulation results. While some of these results (especially the different occupancy rate of the Zeth Merkle tree) may seem surprising at first glance, they are not. In fact, using different curves implies:\n",
    "    - using different precompiled contracts for the state transition (these EVM \"extensions\" have different costs)\n",
    "    - sending different pieces of data on-chain (these data pieces have different byte-length and this incur different cost)\n",
    "\n",
    "Hence switching the curve implies having different transaction costs, which means, a potentially different number of transactions fitting in a block (provided a fixed gas limit per block). This, in fine, impacts the number of commitments added to the Zeth tree per block, hence leading to potentially different occupancy rates for the Merkle tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-flood",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "- As described in the [Zecale paper](https://arxiv.org/abs/2008.05958), using Zecale can allow to have sender anonymity (under additional assumptions) and can allow to save gas and bytes for the nested transactions. Importantly, we know that beyond the existing tension between (trustless) privacy and scalability (i.e. more data needs to be added to the chain to maximize \"undistinguishability\"), there also exists a tension between (trustless) \"privacy\" and \"composability\" on blockchain systems. In fact, manipulating one's funds in a privacy preserving fashion is an impediment to composability (which is fully leveraged in the \"clear\"). \n",
    "- No solution is a silver bullet. Whether \"multi/side-chain\"-based solutions, sharding approaches (somewhat releated to the \"multi-blockchain\" paradigm) or a \"rollup\"/L2 approach is employed, one needs to be aware of the various tradeoffs on composability (challenges around \"cross-rollup execution\"/\"cross-shard execution\"), on decentralization and censorship resistance (potential increased centralization with rollups, potential \"data availability\" violations) etc.\n",
    "\n",
    "In this experiment, we simply modeled various systems under extreme conditions (some where **only** EoA-to-EoA transactions are carried out, some where **only** Zeth transactions are mined). In practice, this is much more nuanced and blocks contain various type of transactions (various \"DApps transactions\", ERC token transactions, plain EoA-to-EoA transactions etc). As such, it is worth remembering that in real-life systems, the number of Zeth transactions is not expected to represent 100% of the chain use. Since Zeth can be used to transact fungible assets (ERC20/223 tokens, ETH etc.), we are interested to get the proportion of block space occupied by such transactions on Ethereum. To that end, we looked at several thousands of Ethereum transactions, which showed that approximatively 85% of them could be carried out in a privacy preserving manner using Zeth on mainnet (i.e. around 85% of the transactions analyzed were EoA-to-EoA transactions or ERC token transactions).\n",
    "\n",
    "Knowing this, along with the known tension between privacy and composability (i.e. manipulating one's funds in a privacy preserving fashion is an impediment to composability (which is fully leveraged in the \"clear\")) - which would likely drive the number of Zeth transaction down (i.e. numerous \"clear-text\" EoA-to-EoA/ERC token transfer transactions would still need to be carried out to compose with DeFi applications on-chain) -, we assume (for illustration purposes), that the number of Zeth transactions represents 50% of the chain \"traffic\". This means, that despite Zeth transactions being approx. 18 times bigger than EoA-to-EoA transactions, using Zeth **does not** translate into a state growing 18 times faster, but rather **50% of the state growing 18 times faster** (for a fixed number of transactions).\n",
    "\n",
    "--------\n",
    "\n",
    "*Note: The high number of EoA-to-EoA transactions seems to be partially due to mining pools that redistribute rewards to participants on the network. Interestingly, it looks like a Zeth contract configured to handle a high `JSOUT` could be used for Zeth multi-private payments within a mining pool. No simulation has been carried out under such configuration however. This is let for future work.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-production",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-belief",
   "metadata": {},
   "source": [
    "This study offers preliminary results about the impact of Zeth on the state growth of the underlying blockchain. While these results are due to be refined in the future, we think they provide an acceptable estimate of the state growth of the system under different conditions.\n",
    "\n",
    "Importantly, for public blockchain networks to be sustainable, we think that all L2 developers *MUST* carry out some analysis to track the impact that their smart-contracts/layer 2 protocols will have on the layer 1 they build upon (be it Ethereum or another one). Doing so before deploying the smart-contracts is particularly important to prevent bloating the system's state which - as we know - is immutable. It is the community's responsibility to protect \"its common goods\" and prevent the so called [\"tragedy of the commons\"](https://science.sciencemag.org/content/162/3859/1243)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-passing",
   "metadata": {},
   "source": [
    "## Up next\n",
    "\n",
    "In the next notebook, we will simulate our systems under different Zecale configurations to study the data compression achieved for different batch sizes. We will see that limited data compression can be achieved without compromising \"data availability\" and censorship resistance. However, if we are ready to compromise \"data availability\" better compression can be achieved. Appropriate tradeoffs are always required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-barcelona",
   "metadata": {},
   "source": [
    "## Additional References\n",
    "\n",
    "- Zeth paper: https://arxiv.org/abs/1904.00905\n",
    "- Zeth specifications: https://github.com/clearmatics/zeth-specifications\n",
    "- Reference implementation: https://github.com/clearmatics/zeth\n",
    "- Chainwipe Gist: https://gist.github.com/karalabe/60be7bef184c8ec286fc7ee2b35b0b5b\n",
    "- The State Growth Problem Facing Blockchains: https://thecontrol.co/state-growth-a-look-at-the-problem-and-its-solutions-6de9d7634b0b\n",
    "- RocksDB wiki: https://github.com/facebook/rocksdb/wiki/Compression\n",
    "- Which database(s) do the ethereum clients use and why? https://ethereum.stackexchange.com/questions/824/which-databases-do-the-ethereum-clients-use-and-why\n",
    "- The Ethereum-blockchain size will not exceed 1TB anytime soon: https://dev.to/5chdn/the-ethereum-blockchain-size-will-not-exceed-1tb-anytime-soon-58a\n",
    "- Lies, Damn Lies And SSD Benchmark Test Result: https://www.seagate.com/gb/en/tech-insights/lies-damn-lies-and-ssd-benchmark-master-ti/\n",
    "- Turbo-Geth: https://github.com/ledgerwatch/turbo-geth\n",
    "- How Nervos is Tackling the State Explosion Problem Facing Smart Contract Blockchains: https://medium.com/nervosnetwork/how-nervos-is-tackling-the-state-explosion-problem-facing-smart-contract-blockchains-a9acc4c5708e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-candle",
   "metadata": {},
   "source": [
    "---------------------\n",
    "\n",
    "<center>Found a mistake, or thinking about a way to improve this document?</center>\n",
    "\n",
    "<center>Great! All contributions are welcomed. To do so, please feel free to open a Pull Request or an Issue on the repository :)</center>\n",
    "\n",
    "---------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
